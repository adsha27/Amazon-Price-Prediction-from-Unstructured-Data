{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6395a72",
   "metadata": {},
   "source": [
    "he V18 Strategy: Training a Model on the Errors (Residual Fitting)\n",
    "Instead of a simple, hand-coded rule engine, we will train a second model whose only job is to predict the errors of our champion V16 model. This is a powerful machine learning technique.\n",
    "\n",
    "The process is as follows:\n",
    "\n",
    "Train the Champion (V16): We train our best model as usual and get its predictions on the validation set.\n",
    "\n",
    "Calculate the Errors (Residuals): We find the difference between the true price and the model's prediction for each item (error = true_price - predicted_price). This represents what the first model failed to learn.\n",
    "\n",
    "Train an \"Error-Corrector\" Model: We train a second, simpler model. Its features are the same, but its target is now the error. It learns the patterns in the data that cause our main model to make mistakes.\n",
    "\n",
    "Create the Final Prediction: The final, corrected prediction is simply: Final Prediction = V16 Prediction + Error-Corrector Prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0788b58c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V16 features created.\n",
      "\n",
      "Training champion V16 model...\n",
      "Training error-corrector model...\n",
      "\n",
      "Evaluating V18 system...\n",
      "\n",
      "--- Model Performance Comparison ---\n",
      "V16 Model SMAPE (champion): 50.8384\n",
      "V18 Model SMAPE (V16 + Error Correction): 55.7419\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import lightgbm as lgb\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# --- 1. Load Data & V16 Feature Engineering ---\n",
    "train_df = pd.read_csv('input/train.csv')\n",
    "train_df = train_df.dropna(subset=['price'])\n",
    "train_df['catalog_content'] = train_df['catalog_content'].astype(str).fillna('')\n",
    "train_df['title'] = train_df['catalog_content'].apply(lambda t: (m.group(1).strip() if (m := re.search(r'^item name:\\s*(.*)', t, re.I | re.M)) else t))\n",
    "def extract_quantity(text):\n",
    "    text = text.lower(); patterns = [r'pack of (\\d+)', r'(\\d+)\\s*[-]?pack', r'(\\d+)\\s*count', r'(\\d+)\\s*per case', r'(\\d+)\\s*pk'];\n",
    "    for p in patterns:\n",
    "        if m:=re.search(p,text): return int(m.group(1))\n",
    "    return 1\n",
    "def extract_all_numerical_features(text):\n",
    "    text = text.lower(); features = {}; unit_map = {'gb': ['gb'],'oz': ['oz', 'ounce'],'inch': ['inch', '\"'],'mp': ['mp'],'lbs': ['lb', 'lbs'],'mah': ['mah'],'watts': ['watts', 'w']}\n",
    "    for fn, u in unit_map.items():\n",
    "        if m := re.search(fr'(\\d+\\.?\\d*)\\s*(?:{\"|\".join(u)})', text): features[f'feat_{fn}'] = float(m.group(1))\n",
    "    return features\n",
    "numerical_features_df = pd.json_normalize(train_df['catalog_content'].apply(extract_all_numerical_features))\n",
    "train_df = pd.concat([train_df.reset_index(drop=True), numerical_features_df], axis=1)\n",
    "train_df['quantity'] = train_df['catalog_content'].apply(extract_quantity)\n",
    "PREMIUM_KEYWORDS = ['solid wood', 'leather', 'gold', 'oled', '4k', 'stainless steel']\n",
    "train_df['premium_keyword_count'] = train_df['catalog_content'].apply(lambda t: sum(k in t.lower() for k in PREMIUM_KEYWORDS))\n",
    "train_df['title_length'] = train_df['title'].str.len().fillna(0)\n",
    "train_df['content_word_count'] = train_df['catalog_content'].str.split().str.len().fillna(0)\n",
    "print(\"V16 features created.\")\n",
    "\n",
    "# --- 2. Create Hold-Out Set ---\n",
    "numerical_cols = [col for col in train_df.columns if col.startswith('feat_')]\n",
    "all_engineered_cols = ['quantity', 'premium_keyword_count', 'title_length', 'content_word_count'] + numerical_cols\n",
    "X = train_df[['catalog_content'] + all_engineered_cols]\n",
    "y = train_df['price']\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "y_train_log = np.log1p(y_train)\n",
    "\n",
    "# --- 3. Train the Champion V16 Model ---\n",
    "print(\"\\nTraining champion V16 model...\")\n",
    "best_params = { 'objective': 'regression_l1', 'n_estimators': 761, 'learning_rate': 0.188, 'num_leaves': 41, 'max_depth': 17, 'random_state': 42, 'n_jobs': -1, 'verbose': -1 }\n",
    "numeric_pipeline = Pipeline(steps=[('imputer', SimpleImputer(strategy='constant', fill_value=0)), ('scaler', StandardScaler())])\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('text', TfidfVectorizer(stop_words='english', max_features=40000, ngram_range=(1, 2)), 'catalog_content'),\n",
    "    ('numeric', numeric_pipeline, all_engineered_cols)\n",
    "])\n",
    "pipeline_v16 = Pipeline(steps=[('preprocessor', preprocessor), ('regressor', lgb.LGBMRegressor(**best_params))])\n",
    "pipeline_v16.fit(X_train, y_train_log)\n",
    "# Get base predictions on the training data to calculate errors\n",
    "train_preds_log_v16 = pipeline_v16.predict(X_train)\n",
    "train_preds_v16 = np.expm1(train_preds_log_v16)\n",
    "train_preds_v16[train_preds_v16 < 0] = 0\n",
    "\n",
    "# --- 4. Train the Error-Corrector Model ---\n",
    "print(\"Training error-corrector model...\")\n",
    "# The target is the error of the V16 model\n",
    "errors = y_train - train_preds_v16\n",
    "# We use a simpler model (fewer estimators) to avoid overfitting to the errors\n",
    "error_corrector_model = Pipeline(steps=[('preprocessor', preprocessor), ('regressor', lgb.LGBMRegressor(n_estimators=150, random_state=42, n_jobs=-1))])\n",
    "error_corrector_model.fit(X_train, errors)\n",
    "\n",
    "# --- 5. Evaluate the Full V18 System ---\n",
    "print(\"\\nEvaluating V18 system...\")\n",
    "# Stage 1: Get base predictions from V16 on the validation set\n",
    "val_preds_log_v16 = pipeline_v16.predict(X_val)\n",
    "val_preds_v16 = np.expm1(val_preds_log_v16)\n",
    "val_preds_v16[val_preds_v16 < 0] = 0\n",
    "# Stage 2: Get error predictions from the corrector model\n",
    "error_preds = error_corrector_model.predict(X_val)\n",
    "# Stage 3: Combine the predictions\n",
    "final_predictions = val_preds_v16 + error_preds\n",
    "final_predictions[final_predictions < 0] = 0\n",
    "\n",
    "def smape(y_true, y_pred):\n",
    "    num = np.abs(y_pred - y_true); den = (np.abs(y_true) + np.abs(y_pred)) / 2\n",
    "    return np.mean(np.divide(num, den, out=np.zeros_like(num, dtype=float), where=den!=0)) * 100\n",
    "\n",
    "v16_smape = smape(y_val, val_preds_v16)\n",
    "v18_smape = smape(y_val, final_predictions)\n",
    "\n",
    "print(\"\\n--- Model Performance Comparison ---\")\n",
    "print(f\"V16 Model SMAPE (champion): {v16_smape:.4f}\")\n",
    "print(f\"V18 Model SMAPE (V16 + Error Correction): {v18_smape:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bc4ce8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "price_predictor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
