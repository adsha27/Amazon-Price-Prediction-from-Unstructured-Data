{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "db37d251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data loaded successfully.\n",
      "Data shape after cleaning: (74983, 6)\n",
      "Created 'price_per_unit' target.\n",
      "\n",
      "Training V3 PPU model...\n",
      "\n",
      "Evaluating V3 PPU model...\n",
      "\n",
      "--- Model Performance Comparison ---\n",
      "V1 Model SMAPE (text only, predicting total price): 51.9241\n",
      "V3 Model SMAPE (predicting price-per-unit): 53.6539\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# --- 1. Load Data ---\n",
    "train_df = pd.read_csv('/Users/adityasharma/Github Projects/Amazon/input/train.csv')\n",
    "train_df = train_df.dropna(subset=['price'])\n",
    "train_df['catalog_content'] = train_df['catalog_content'].astype(str).fillna('')\n",
    "print(\"Training data loaded successfully.\")\n",
    "\n",
    "# --- 2. Feature Engineering ---\n",
    "def extract_quantity(text):\n",
    "    text = text.lower()\n",
    "    patterns = [\n",
    "        r'pack of (\\d+)', r'(\\d+)\\s*[-]?pack', r'(\\d+)\\s*pk', r'(\\d+)\\s*per case', r'case of (\\d+)',\n",
    "        r'(\\d+)\\s*count', r'(\\d+)\\s*ct', r'(\\d+)\\s*ea', r'total (\\d+)', r'(\\d+)\\s*servings',\n",
    "        r'(\\d+)\\s*pcs', r'(\\d+)\\s*stems'\n",
    "    ]\n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, text)\n",
    "        if match: return int(match.group(1))\n",
    "    return 1\n",
    "\n",
    "def extract_brand(text):\n",
    "    # This is a simplified extractor; we can make it more robust later.\n",
    "    match = re.search(r'^(?:brand|manufacturer):\\s*(.*)', text, re.IGNORECASE | re.MULTILINE)\n",
    "    if match: return match.group(1).strip().lower()\n",
    "    return 'unknown'\n",
    "\n",
    "train_df['quantity'] = train_df['catalog_content'].apply(extract_quantity)\n",
    "train_df['brand'] = train_df['catalog_content'].apply(extract_brand)\n",
    "\n",
    "# Remove rows where quantity is 0 to avoid division by zero\n",
    "train_df = train_df[train_df['quantity'] > 0]\n",
    "print(f\"Data shape after cleaning: {train_df.shape}\")\n",
    "\n",
    "# --- 3. Create the New Price-Per-Unit Target ---\n",
    "train_df['price_per_unit'] = train_df['price'] / train_df['quantity']\n",
    "print(\"Created 'price_per_unit' target.\")\n",
    "\n",
    "# --- 4. Create Hold-Out Set ---\n",
    "X = train_df[['catalog_content', 'quantity', 'brand']]\n",
    "y = train_df[['price', 'price_per_unit', 'quantity']] # Pass all needed columns for evaluation\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "y_train_log_ppu = np.log1p(y_train['price_per_unit'])\n",
    "\n",
    "# --- 5. Build the V3 Pipeline ---\n",
    "best_params = {\n",
    "    'objective': 'regression_l1', 'metric': 'mae', 'n_estimators': 761, 'learning_rate': 0.188,\n",
    "    'num_leaves': 41, 'max_depth': 17, 'lambda_l1': 0.04, 'lambda_l2': 2.53e-06,\n",
    "    'feature_fraction': 0.73, 'bagging_fraction': 0.81, 'bagging_freq': 5,\n",
    "    'min_child_samples': 9, 'random_state': 42, 'n_jobs': -1, 'verbose': -1\n",
    "}\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('text', TfidfVectorizer(stop_words='english', max_features=30000, ngram_range=(1, 2)), 'catalog_content'),\n",
    "        ('brand', OneHotEncoder(handle_unknown='ignore'), ['brand']),\n",
    "        ('numeric', 'passthrough', ['quantity'])\n",
    "    ])\n",
    "\n",
    "pipeline_v3 = Pipeline(steps=[('preprocessor', preprocessor), ('regressor', lgb.LGBMRegressor(**best_params))])\n",
    "\n",
    "# --- 6. Train and Evaluate ---\n",
    "print(\"\\nTraining V3 PPU model...\")\n",
    "pipeline_v3.fit(X_train, y_train_log_ppu)\n",
    "\n",
    "print(\"\\nEvaluating V3 PPU model...\")\n",
    "val_preds_log_ppu = pipeline_v3.predict(X_val)\n",
    "val_preds_ppu = np.expm1(val_preds_log_ppu)\n",
    "val_preds_ppu[val_preds_ppu < 0] = 0\n",
    "\n",
    "# Reconstruct the final price from the per-unit prediction\n",
    "final_predictions = val_preds_ppu * X_val['quantity']\n",
    "\n",
    "def smape(y_true, y_pred):\n",
    "    numerator = np.abs(y_pred - y_true)\n",
    "    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2\n",
    "    return np.mean(np.divide(numerator, denominator, out=np.zeros_like(numerator, dtype=float), where=denominator!=0)) * 100\n",
    "\n",
    "v3_smape = smape(y_val['price'], final_predictions)\n",
    "\n",
    "print(\"\\n--- Model Performance Comparison ---\")\n",
    "print(f\"V1 Model SMAPE (text only, predicting total price): 51.9241\")\n",
    "print(f\"V3 Model SMAPE (predicting price-per-unit): {v3_smape:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e759a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (housing-price-prediction)",
   "language": "python",
   "name": "housing-price-prediction"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
