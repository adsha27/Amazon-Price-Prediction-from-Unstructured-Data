{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7867286a",
   "metadata": {},
   "source": [
    "Our system will work as follows:\n",
    "\n",
    "Train our champion V8 model as usual to get a base_prediction.\n",
    "\n",
    "Extract the quantity and category features from the text.\n",
    "\n",
    "Apply a set of corrective rules to the base_prediction based on the features.\n",
    "\n",
    "The rules will be designed to fix the two error types we know exist:\n",
    "\n",
    "Rule 1 (Fixing Under-prediction): The \"Bulk Item\" Correction. If the model predicts a very low price for an item that has a large quantity and does not seem to be a cheap grocery item, we hypothesize the model has predicted the unit price. We will correct this by multiplying by the quantity.\n",
    "\n",
    "Rule 2 (Fixing Over-prediction): The \"Grocery Case\" Correction. If the model predicts a very high price for an item that has a large quantity and seems to be a cheap grocery item, we hypothesize the model has predicted the case price when the label is the unit price. We will correct this by dividing by the quantity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f8697b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features created.\n",
      "\n",
      "Training the base V8 model...\n",
      "Applying post-processing rule engine...\n",
      "\n",
      "--- Model Performance Comparison ---\n",
      "V8 Model SMAPE (before rules): 51.1591\n",
      "V17 Model SMAPE (after rules): 61.6941\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import lightgbm as lgb\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# --- 1. Load Data and Engineer All V8 Features ---\n",
    "train_df = pd.read_csv('input/train.csv')\n",
    "train_df = train_df.dropna(subset=['price'])\n",
    "train_df['catalog_content'] = train_df['catalog_content'].astype(str).fillna('')\n",
    "def extract_quantity(text):\n",
    "    text = text.lower(); patterns = [r'pack of (\\d+)', r'(\\d+)\\s*[-]?pack', r'(\\d+)\\s*count', r'(\\d+)\\s*per case', r'(\\d+)\\s*pk'];\n",
    "    for p in patterns:\n",
    "        if m:=re.search(p,text): return int(m.group(1))\n",
    "    return 1\n",
    "def extract_numerical_features(text):\n",
    "    text = text.lower(); features = {}; unit_map = {'gb': ['gb'],'oz': ['oz', 'ounce'],'inch': ['inch', '\"'],'mp': ['mp'],'lbs': ['lb', 'lbs']}\n",
    "    for fn, u in unit_map.items():\n",
    "        if m := re.search(fr'(\\d+\\.?\\d*)\\s*(?:{\"|\".join(u)})', text): features[f'feat_{fn}'] = float(m.group(1))\n",
    "    return features\n",
    "numerical_features_df = pd.json_normalize(train_df['catalog_content'].apply(extract_numerical_features))\n",
    "train_df = pd.concat([train_df.reset_index(drop=True), numerical_features_df], axis=1)\n",
    "train_df['quantity'] = train_df['catalog_content'].apply(extract_quantity)\n",
    "def categorize_product(text):\n",
    "    if any(k in text.lower() for k in ['coffee', 'tea', 'snack', 'candy', 'gum', 'soda', 'sauce']): return 'grocery'\n",
    "    return 'non-grocery'\n",
    "train_df['category'] = train_df['catalog_content'].apply(categorize_product)\n",
    "print(\"Features created.\")\n",
    "\n",
    "# --- 2. Create Hold-Out Set ---\n",
    "numerical_cols = [col for col in train_df.columns if col.startswith('feat_')]\n",
    "X = train_df[['catalog_content', 'quantity', 'category'] + numerical_cols]\n",
    "y = train_df['price']\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "y_train_log = np.log1p(y_train)\n",
    "\n",
    "# --- 3. Train the V8 Model ---\n",
    "print(\"\\nTraining the base V8 model...\")\n",
    "best_params = { 'objective': 'regression_l1', 'n_estimators': 761, 'learning_rate': 0.188, 'num_leaves': 41, 'max_depth': 17, 'random_state': 42, 'n_jobs': -1, 'verbose': -1 }\n",
    "numeric_pipeline = Pipeline(steps=[('imputer', SimpleImputer(strategy='constant', fill_value=0)), ('scaler', StandardScaler())])\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('text', TfidfVectorizer(stop_words='english', max_features=30000, ngram_range=(1, 2)), 'catalog_content'),\n",
    "    ('numeric', numeric_pipeline, ['quantity'] + numerical_cols)\n",
    "], remainder='drop')\n",
    "pipeline_v8 = Pipeline(steps=[('preprocessor', preprocessor), ('regressor', lgb.LGBMRegressor(**best_params))])\n",
    "pipeline_v8.fit(X_train, y_train_log)\n",
    "base_preds_log = pipeline_v8.predict(X_val)\n",
    "base_preds = np.expm1(base_preds_log)\n",
    "base_preds[base_preds < 0] = 0\n",
    "\n",
    "# --- 4. Apply the Post-Processing Rule Engine ---\n",
    "print(\"Applying post-processing rule engine...\")\n",
    "analysis_df = X_val.copy()\n",
    "analysis_df['base_prediction'] = base_preds\n",
    "\n",
    "def apply_price_rules(row):\n",
    "    # Rule 1: Fix Under-prediction for expensive-seeming bulk items\n",
    "    if row['quantity'] > 1 and row['base_prediction'] < 20 and row['category'] != 'grocery':\n",
    "        return row['base_prediction'] * row['quantity']\n",
    "    # Rule 2: Fix Over-prediction for cheap grocery bulk items\n",
    "    if row['quantity'] > 1 and row['base_prediction'] > 50 and row['category'] == 'grocery':\n",
    "        return row['base_prediction'] / row['quantity']\n",
    "    # If no rule applies, keep the original prediction\n",
    "    return row['base_prediction']\n",
    "\n",
    "analysis_df['corrected_prediction'] = analysis_df.apply(apply_price_rules, axis=1)\n",
    "\n",
    "# --- 5. Evaluate and Compare ---\n",
    "def smape(y_true, y_pred):\n",
    "    num = np.abs(y_pred - y_true); den = (np.abs(y_true) + np.abs(y_pred)) / 2\n",
    "    return np.mean(np.divide(num, den, out=np.zeros_like(num, dtype=float), where=den!=0)) * 100\n",
    "\n",
    "base_smape = smape(y_val, analysis_df['base_prediction'])\n",
    "corrected_smape = smape(y_val, analysis_df['corrected_prediction'])\n",
    "\n",
    "print(\"\\n--- Model Performance Comparison ---\")\n",
    "print(f\"V8 Model SMAPE (before rules): {base_smape:.4f}\")\n",
    "print(f\"V17 Model SMAPE (after rules): {corrected_smape:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720e96a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "price_predictor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
