{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5ed5c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading Data and Pre-processing Embeddings ---\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fe3009821ab41e1bfbbd5a0ca65da1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Mapping Embeddings: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Engineering V16 Features ---\n",
      "\n",
      "--- Splitting Data and Building Feature Matrices ---\n",
      "\n",
      "--- Training Screener and Expert Models ---\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 6.733310 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1780064\n",
      "[LightGBM] [Info] Number of data points in the train set: 60000, number of used features: 38631\n",
      "[LightGBM] [Info] Start training from score 2.740904\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 7.221616 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1910624\n",
      "[LightGBM] [Info] Number of data points in the train set: 60000, number of used features: 39143\n",
      "[LightGBM] [Info] Start training from score 2.740904\n",
      "\n",
      "--- Tuning the Routing Threshold on Validation Set ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/adityasharma/miniforge3/envs/price_predictor/lib/python3.11/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMRegressor was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "947a6b9b30594669a209555de6d34e37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tuning Threshold:   0%|          | 0/21 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Optimal Routing Threshold found: $55\n",
      "V16 (Text-Only) SMAPE: 55.8953\n",
      "V17 (Text+Image) SMAPE: 55.1005\n",
      "T-1 Dynamic Router SMAPE: 55.9075\n",
      "\n",
      "❌ Failure. The Dynamic Model Router did not improve upon the best single model.\n",
      "\n",
      "--- Saving T-1 Model Artifacts ---\n",
      "All T-1 model components saved to: output/t-1_dynamic_model_router.pkl\n"
     ]
    }
   ],
   "source": [
    "# --- 1. SETUP & CONFIGURATION ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from scipy.sparse import hstack\n",
    "import lightgbm as lgb\n",
    "import os\n",
    "import re\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "INPUT_DIR = 'input/'\n",
    "OUTPUT_DIR = 'output/'\n",
    "EXPERIMENT_NAME = 't-1_dynamic_model_router'\n",
    "CHAMPION_BENCHMARK_SMAPE = 50.43\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "def smape(y_true, y_pred):\n",
    "    numerator = np.abs(y_pred - y_true)\n",
    "    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2\n",
    "    return np.mean(numerator / (denominator + 1e-8)) * 100\n",
    "\n",
    "# --- 2. DATA & EMBEDDING PREP ---\n",
    "print(\"--- Loading Data and Pre-processing Embeddings ---\")\n",
    "train_df_full = pd.read_csv(os.path.join(INPUT_DIR, 'train.csv'), index_col='sample_id')\n",
    "test_df_full = pd.read_csv(os.path.join(INPUT_DIR, 'test.csv'), index_col='sample_id')\n",
    "with open(os.path.join(INPUT_DIR, 'final_embeddings.pkl'), 'rb') as f:\n",
    "    image_embeddings_dict = pickle.load(f)\n",
    "\n",
    "# Create the fast lookup matrix for embeddings\n",
    "all_df = pd.concat([train_df_full, test_df_full])\n",
    "max_id = all_df.index.max()\n",
    "embedding_matrix = np.zeros((max_id + 1, 512), dtype=np.float32)\n",
    "for sample_id, row in tqdm(all_df.iterrows(), desc=\"Mapping Embeddings\"):\n",
    "    embedding = image_embeddings_dict.get(row['image_link'])\n",
    "    if embedding is not None:\n",
    "        embedding_matrix[sample_id] = embedding\n",
    "\n",
    "# --- 3. FEATURE ENGINEERING (V16 Pipeline) ---\n",
    "print(\"\\n--- Engineering V16 Features ---\")\n",
    "train_df = train_df_full.dropna(subset=['catalog_content', 'price', 'image_link']).copy()\n",
    "train_df['log_price'] = np.log1p(train_df['price'])\n",
    "\n",
    "# Comprehensive numerical features from V16 summary\n",
    "units = ['gb', 'oz', 'inch', 'mah', 'count', 'pack', 'mp', 'lbs', 'watts']\n",
    "for unit in units:\n",
    "    regex = r'(\\d+\\.?\\d*)\\s?' + re.escape(unit)\n",
    "    train_df[f'feat_{unit}'] = train_df['catalog_content'].str.extract(regex, flags=re.IGNORECASE).astype(float).fillna(0)\n",
    "train_df['feat_premium_keyword_count'] = train_df['catalog_content'].str.lower().str.count('pro|plus|premium|deluxe')\n",
    "train_df['feat_word_count'] = train_df['catalog_content'].str.split().str.len()\n",
    "\n",
    "# --- 4. DATA SPLIT & FEATURE MATRIX CONSTRUCTION ---\n",
    "print(\"\\n--- Splitting Data and Building Feature Matrices ---\")\n",
    "X_train_df, X_val_df = train_test_split(train_df, test_size=0.2, random_state=RANDOM_STATE)\n",
    "y_train_log, y_val = X_train_df['log_price'], X_val_df['price']\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=40000, ngram_range=(1, 2))\n",
    "numerical_cols = [col for col in train_df.columns if col.startswith('feat_')]\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Create V16 (text-only) features\n",
    "X_train_tfidf = tfidf.fit_transform(X_train_df['catalog_content'])\n",
    "X_train_num = scaler.fit_transform(X_train_df[numerical_cols])\n",
    "X_train_v16 = hstack([X_train_tfidf, X_train_num], format='csr')\n",
    "\n",
    "# Create V17 (text + image) features\n",
    "X_train_img = embedding_matrix[X_train_df.index]\n",
    "X_train_v17 = hstack([X_train_v16, X_train_img], format='csr')\n",
    "\n",
    "# --- 5. TRAIN THE ROUTER & EXPERTS ---\n",
    "print(\"\\n--- Training Screener and Expert Models ---\")\n",
    "# Train Screener (fast model)\n",
    "screener_model = Ridge(random_state=RANDOM_STATE)\n",
    "screener_model.fit(X_train_tfidf, y_train_log)\n",
    "\n",
    "# Train V16 Expert (text-only)\n",
    "expert_v16 = lgb.LGBMRegressor(random_state=RANDOM_STATE)\n",
    "expert_v16.fit(X_train_v16, y_train_log)\n",
    "\n",
    "# Train V17 Expert (text + image)\n",
    "expert_v17 = lgb.LGBMRegressor(random_state=RANDOM_STATE)\n",
    "expert_v17.fit(X_train_v17, y_train_log)\n",
    "\n",
    "# --- 6. TUNE THE ROUTING THRESHOLD ---\n",
    "print(\"\\n--- Tuning the Routing Threshold on Validation Set ---\")\n",
    "# Prepare validation features\n",
    "X_val_tfidf = tfidf.transform(X_val_df['catalog_content'])\n",
    "X_val_num = scaler.transform(X_val_df[numerical_cols])\n",
    "X_val_img = embedding_matrix[X_val_df.index]\n",
    "X_val_v16 = hstack([X_val_tfidf, X_val_num], format='csr')\n",
    "X_val_v17 = hstack([X_val_v16, X_val_img], format='csr')\n",
    "\n",
    "# Get predictions from screener and both experts\n",
    "screener_preds_log = screener_model.predict(X_val_tfidf)\n",
    "screener_preds = np.expm1(screener_preds_log)\n",
    "expert_v16_preds = np.expm1(expert_v16.predict(X_val_v16))\n",
    "expert_v17_preds = np.expm1(expert_v17.predict(X_val_v17))\n",
    "\n",
    "best_smape = float('inf')\n",
    "best_threshold = 0\n",
    "thresholds_to_test = np.arange(50, 151, 5) # Test thresholds from $50 to $150\n",
    "\n",
    "for threshold in tqdm(thresholds_to_test, desc=\"Tuning Threshold\"):\n",
    "    # Apply routing logic\n",
    "    final_preds = np.where(screener_preds >= threshold, expert_v17_preds, expert_v16_preds)\n",
    "    current_smape = smape(y_val, final_preds)\n",
    "    if current_smape < best_smape:\n",
    "        best_smape = current_smape\n",
    "        best_threshold = threshold\n",
    "\n",
    "print(f\"\\nOptimal Routing Threshold found: ${best_threshold}\")\n",
    "print(f\"V16 (Text-Only) SMAPE: {smape(y_val, expert_v16_preds):.4f}\")\n",
    "print(f\"V17 (Text+Image) SMAPE: {smape(y_val, expert_v17_preds):.4f}\")\n",
    "print(f\"T-1 Dynamic Router SMAPE: {best_smape:.4f}\")\n",
    "\n",
    "# --- 7. FINAL EVALUATION & CONCLUSION ---\n",
    "improvement = CHAMPION_BENCHMARK_SMAPE - best_smape\n",
    "if improvement > 0:\n",
    "    print(f\"\\n✅ Success. The Dynamic Model Router improved the SMAPE by {improvement:.4f} points.\")\n",
    "else:\n",
    "    print(f\"\\n❌ Failure. The Dynamic Model Router did not improve upon the best single model.\")\n",
    "\n",
    "# --- 8. SAVE THE FINAL ARTIFACTS ---\n",
    "print(\"\\n--- Saving T-1 Model Artifacts ---\")\n",
    "artifacts = {\n",
    "    'screener_model': screener_model,\n",
    "    'expert_v16_model': expert_v16,\n",
    "    'expert_v17_model': expert_v17,\n",
    "    'tfidf_vectorizer': tfidf,\n",
    "    'numerical_scaler': scaler,\n",
    "    'numerical_columns': numerical_cols,\n",
    "    'routing_threshold': best_threshold,\n",
    "    'version': EXPERIMENT_NAME\n",
    "}\n",
    "output_path = os.path.join(OUTPUT_DIR, f\"{EXPERIMENT_NAME}.pkl\")\n",
    "with open(output_path, 'wb') as f:\n",
    "    pickle.dump(artifacts, f)\n",
    "print(f\"All T-1 model components saved to: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f546037",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "price_predictor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
