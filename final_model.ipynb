{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f32432da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data loaded successfully.\n",
      "\n",
      "Training final model on the 80% training split...\n",
      "Training complete.\n",
      "\n",
      "Evaluating model on the hold-out validation set...\n",
      "\n",
      "--- Final Model Performance ---\n",
      "SMAPE on hold-out validation set: 51.9241\n",
      "\n",
      "Model trained on 80% of data saved to 'lgbm_price_model_v1.joblib'\n",
      "\n",
      "Retraining model on 100% of training data for final submission...\n",
      "Submission file 'submission.csv' created.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# --- 1. Define File Paths ---\n",
    "train_file_path = '/Users/adityasharma/Github Projects/Amazon/input/train.csv'\n",
    "final_test_file_path = '/Users/adityasharma/Github Projects/Amazon/input/test.csv'\n",
    "\n",
    "# --- 2. Load Training Data ---\n",
    "try:\n",
    "    df = pd.read_csv(train_file_path)\n",
    "    df = df.dropna(subset=['price'])\n",
    "    df['catalog_content'] = df['catalog_content'].astype(str).fillna('')\n",
    "    print(\"Training data loaded successfully.\")\n",
    "except FileNotFoundError as e:\n",
    "    print(e); raise\n",
    "\n",
    "# --- 3. Create Feature and Target Sets ---\n",
    "X = df['catalog_content']\n",
    "y = df['price']\n",
    "# --- FIX: Define y_log for the full dataset here ---\n",
    "y_log = np.log1p(y)\n",
    "\n",
    "# Create a final hold-out validation set for scoring\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "y_train_log = np.log1p(y_train)\n",
    "\n",
    "# --- 4. Define the Final Model with Best Parameters ---\n",
    "best_params = {\n",
    "    'objective': 'regression_l1', 'metric': 'mae',\n",
    "    'n_estimators': 761, 'learning_rate': 0.1884930281597436,\n",
    "    'num_leaves': 41, 'max_depth': 17, 'lambda_l1': 0.040587974507707486,\n",
    "    'lambda_l2': 2.538242194369503e-06, 'feature_fraction': 0.7302844764184871,\n",
    "    'bagging_fraction': 0.8115111618141515, 'bagging_freq': 5,\n",
    "    'min_child_samples': 9, 'random_state': 42, 'n_jobs': -1, 'verbose': -1\n",
    "}\n",
    "\n",
    "final_pipeline = make_pipeline(\n",
    "    TfidfVectorizer(stop_words='english', max_features=30000, ngram_range=(1, 2)),\n",
    "    lgb.LGBMRegressor(**best_params)\n",
    ")\n",
    "\n",
    "# --- 5. Train the Model on the Training Portion ---\n",
    "print(\"\\nTraining final model on the 80% training split...\")\n",
    "final_pipeline.fit(X_train, y_train_log)\n",
    "print(\"Training complete.\")\n",
    "\n",
    "# --- 6. Evaluate on the 20% Hold-Out Validation Set ---\n",
    "print(\"\\nEvaluating model on the hold-out validation set...\")\n",
    "val_preds_log = final_pipeline.predict(X_val)\n",
    "val_preds = np.expm1(val_preds_log)\n",
    "val_preds[val_preds < 0] = 0\n",
    "\n",
    "def smape(y_true, y_pred):\n",
    "    numerator = np.abs(y_pred - y_true)\n",
    "    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2\n",
    "    return np.mean(np.divide(numerator, denominator, out=np.zeros_like(numerator, dtype=float), where=denominator!=0)) * 100\n",
    "\n",
    "final_validation_smape = smape(y_val, val_preds)\n",
    "\n",
    "print(\"\\n--- Final Model Performance ---\")\n",
    "print(f\"SMAPE on hold-out validation set: {final_validation_smape:.4f}\")\n",
    "\n",
    "# --- 7. Save the Model ---\n",
    "model_filename = 'lgbm_price_model_v1.joblib'\n",
    "joblib.dump(final_pipeline, model_filename)\n",
    "print(f\"\\nModel trained on 80% of data saved to '{model_filename}'\")\n",
    "\n",
    "# --- 8. (Optional) Create Submission File ---\n",
    "print(\"\\nRetraining model on 100% of training data for final submission...\")\n",
    "# This will now work because y_log is defined for the full dataset\n",
    "final_pipeline.fit(X, y_log)\n",
    "final_test_df = pd.read_csv(final_test_file_path)\n",
    "X_final_test = final_test_df['catalog_content'].astype(str).fillna('')\n",
    "final_predictions_log = final_pipeline.predict(X_final_test)\n",
    "final_predictions = np.expm1(final_predictions_log)\n",
    "final_predictions[final_predictions < 0] = 0\n",
    "\n",
    "submission_df = pd.DataFrame({'id': final_test_df.index, 'price': final_predictions})\n",
    "submission_df.to_csv('submission.csv', index=False)\n",
    "print(\"Submission file 'submission.csv' created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e61971",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (housing-price-prediction)",
   "language": "python",
   "name": "housing-price-prediction"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
