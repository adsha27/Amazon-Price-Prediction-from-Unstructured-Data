{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f9ccf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm\n",
      "  Downloading lightgbm-4.6.0.tar.gz (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting numpy>=1.17.0 (from lightgbm)\n",
      "  Downloading numpy-2.3.3.tar.gz (20.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.6/20.6 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting scipy (from lightgbm)\n",
      "  Downloading scipy-1.16.2.tar.gz (30.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.6/30.6 MB\u001b[0m \u001b[31m38.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mPreparing metadata \u001b[0m\u001b[1;32m(\u001b[0m\u001b[32mpyproject.toml\u001b[0m\u001b[1;32m)\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[82 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m \u001b[36m\u001b[1m+ meson setup /private/var/folders/1k/7lydcyq13sl0zlx371zkb4xc0000gn/T/pip-install-ec85wvhl/scipy_299d2e63bbb648998f8b33e0b3749b27 /private/var/folders/1k/7lydcyq13sl0zlx371zkb4xc0000gn/T/pip-install-ec85wvhl/scipy_299d2e63bbb648998f8b33e0b3749b27/.mesonpy-who4r3qd -Dbuildtype=release -Db_ndebug=if-release -Db_vscrt=md --native-file=/private/var/folders/1k/7lydcyq13sl0zlx371zkb4xc0000gn/T/pip-install-ec85wvhl/scipy_299d2e63bbb648998f8b33e0b3749b27/.mesonpy-who4r3qd/meson-python-native-file.ini\u001b[0m\n",
      "  \u001b[31m   \u001b[0m The Meson build system\n",
      "  \u001b[31m   \u001b[0m Version: 1.9.0\n",
      "  \u001b[31m   \u001b[0m Source dir: /private/var/folders/1k/7lydcyq13sl0zlx371zkb4xc0000gn/T/pip-install-ec85wvhl/scipy_299d2e63bbb648998f8b33e0b3749b27\n",
      "  \u001b[31m   \u001b[0m Build dir: /private/var/folders/1k/7lydcyq13sl0zlx371zkb4xc0000gn/T/pip-install-ec85wvhl/scipy_299d2e63bbb648998f8b33e0b3749b27/.mesonpy-who4r3qd\n",
      "  \u001b[31m   \u001b[0m Build type: native build\n",
      "  \u001b[31m   \u001b[0m Project name: scipy\n",
      "  \u001b[31m   \u001b[0m Project version: 1.16.2\n",
      "  \u001b[31m   \u001b[0m C compiler for the host machine: /opt/homebrew/opt/llvm/bin/clang (clang 21.1.3 \"Homebrew clang version 21.1.3\")\n",
      "  \u001b[31m   \u001b[0m C linker for the host machine: /opt/homebrew/opt/llvm/bin/clang ld64 1167.5\n",
      "  \u001b[31m   \u001b[0m C++ compiler for the host machine: /opt/homebrew/opt/llvm/bin/clang++ (clang 21.1.3 \"Homebrew clang version 21.1.3\")\n",
      "  \u001b[31m   \u001b[0m C++ linker for the host machine: /opt/homebrew/opt/llvm/bin/clang++ ld64 1167.5\n",
      "  \u001b[31m   \u001b[0m Cython compiler for the host machine: cython (cython 3.1.4)\n",
      "  \u001b[31m   \u001b[0m Host machine cpu family: aarch64\n",
      "  \u001b[31m   \u001b[0m Host machine cpu: aarch64\n",
      "  \u001b[31m   \u001b[0m Program python found: YES (/Users/adityasharma/.pyenv/versions/3.11.0/bin/python3.11)\n",
      "  \u001b[31m   \u001b[0m Found pkg-config: YES (/opt/homebrew/bin/pkg-config) 2.4.3\n",
      "  \u001b[31m   \u001b[0m Run-time dependency python found: YES 3.11\n",
      "  \u001b[31m   \u001b[0m Program cython found: YES (/private/var/folders/1k/7lydcyq13sl0zlx371zkb4xc0000gn/T/pip-build-env-0pfua3wg/overlay/bin/cython)\n",
      "  \u001b[31m   \u001b[0m Compiler for C supports arguments -Wno-unused-but-set-variable: YES\n",
      "  \u001b[31m   \u001b[0m Compiler for C supports arguments -Wno-unused-function: YES\n",
      "  \u001b[31m   \u001b[0m Compiler for C supports arguments -Wno-conversion: YES\n",
      "  \u001b[31m   \u001b[0m Compiler for C supports arguments -Wno-misleading-indentation: YES\n",
      "  \u001b[31m   \u001b[0m Library m found: YES\n",
      "  \u001b[31m   \u001b[0m Fortran compiler for the host machine: gfortran (gcc 15.2.0 \"GNU Fortran (Homebrew GCC 15.2.0) 15.2.0\")\n",
      "  \u001b[31m   \u001b[0m Fortran linker for the host machine: gfortran ld64 1167.5\n",
      "  \u001b[31m   \u001b[0m ../meson.build:94: WARNING: Consider using the built-in option for language standard version instead of using \"-std=legacy\".\n",
      "  \u001b[31m   \u001b[0m Compiler for Fortran supports arguments -Wno-conversion: YES\n",
      "  \u001b[31m   \u001b[0m Compiler for C supports link arguments -Wl,-dead_strip: YES\n",
      "  \u001b[31m   \u001b[0m Checking if \"-Wl,--version-script\" links: NO\n",
      "  \u001b[31m   \u001b[0m Program tools/generate_f2pymod.py found: YES (/Users/adityasharma/.pyenv/versions/3.11.0/bin/python3.11 /private/var/folders/1k/7lydcyq13sl0zlx371zkb4xc0000gn/T/pip-install-ec85wvhl/scipy_299d2e63bbb648998f8b33e0b3749b27/tools/generate_f2pymod.py)\n",
      "  \u001b[31m   \u001b[0m Program scipy/_build_utils/tempita.py found: YES (/Users/adityasharma/.pyenv/versions/3.11.0/bin/python3.11 /private/var/folders/1k/7lydcyq13sl0zlx371zkb4xc0000gn/T/pip-install-ec85wvhl/scipy_299d2e63bbb648998f8b33e0b3749b27/scipy/_build_utils/tempita.py)\n",
      "  \u001b[31m   \u001b[0m Program pythran found: YES 0.18.0 0.18.0 (/private/var/folders/1k/7lydcyq13sl0zlx371zkb4xc0000gn/T/pip-build-env-0pfua3wg/overlay/bin/pythran)\n",
      "  \u001b[31m   \u001b[0m Found CMake: /opt/homebrew/bin/cmake (3.31.6)\n",
      "  \u001b[31m   \u001b[0m Run-time dependency xsimd found: NO (tried pkgconfig, framework and cmake)\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Executing subproject xsf\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m xsf| Project name: xsf\n",
      "  \u001b[31m   \u001b[0m xsf| Project version: 0.1.0\n",
      "  \u001b[31m   \u001b[0m xsf| C++ compiler for the host machine: /opt/homebrew/opt/llvm/bin/clang++ (clang 21.1.3 \"Homebrew clang version 21.1.3\")\n",
      "  \u001b[31m   \u001b[0m xsf| C++ linker for the host machine: /opt/homebrew/opt/llvm/bin/clang++ ld64 1167.5\n",
      "  \u001b[31m   \u001b[0m xsf| Build targets in project: 0\n",
      "  \u001b[31m   \u001b[0m xsf| Subproject xsf finished.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Executing subproject boost_math\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m boost_math| Project name: boost-math\n",
      "  \u001b[31m   \u001b[0m boost_math| Project version: 1.88.0\n",
      "  \u001b[31m   \u001b[0m boost_math| Build targets in project: 0\n",
      "  \u001b[31m   \u001b[0m boost_math| Subproject boost_math finished.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Executing subproject qhull_r\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m qhull_r| Project name: qhull_r\n",
      "  \u001b[31m   \u001b[0m qhull_r| Project version: 8.0.2\n",
      "  \u001b[31m   \u001b[0m qhull_r| C compiler for the host machine: /opt/homebrew/opt/llvm/bin/clang (clang 21.1.3 \"Homebrew clang version 21.1.3\")\n",
      "  \u001b[31m   \u001b[0m qhull_r| C linker for the host machine: /opt/homebrew/opt/llvm/bin/clang ld64 1167.5\n",
      "  \u001b[31m   \u001b[0m qhull_r| Compiler for C supports arguments -Wno-unused-but-set-variable: YES (cached)\n",
      "  \u001b[31m   \u001b[0m qhull_r| Build targets in project: 1\n",
      "  \u001b[31m   \u001b[0m qhull_r| Subproject qhull_r finished.\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Run-time dependency threads found: YES\n",
      "  \u001b[31m   \u001b[0m numpy-config found: YES (/private/var/folders/1k/7lydcyq13sl0zlx371zkb4xc0000gn/T/pip-build-env-0pfua3wg/overlay/bin/numpy-config) 2.3.3\n",
      "  \u001b[31m   \u001b[0m Run-time dependency numpy found: YES 2.3.3\n",
      "  \u001b[31m   \u001b[0m Library npymath found: YES\n",
      "  \u001b[31m   \u001b[0m pybind11-config found: YES (/private/var/folders/1k/7lydcyq13sl0zlx371zkb4xc0000gn/T/pip-build-env-0pfua3wg/overlay/bin/pybind11-config) 3.0.1\n",
      "  \u001b[31m   \u001b[0m Run-time dependency pybind11 found: YES 3.0.1\n",
      "  \u001b[31m   \u001b[0m Checking if \"thread_local\" compiles: NO\n",
      "  \u001b[31m   \u001b[0m Checking if \"_Thread_local\" compiles: YES\n",
      "  \u001b[31m   \u001b[0m Checking if \"__thread\" compiles: YES\n",
      "  \u001b[31m   \u001b[0m Configuring scipy_config.h using configuration\n",
      "  \u001b[31m   \u001b[0m Program f2py found: YES (/private/var/folders/1k/7lydcyq13sl0zlx371zkb4xc0000gn/T/pip-build-env-0pfua3wg/overlay/bin/f2py)\n",
      "  \u001b[31m   \u001b[0m Run-time dependency scipy-openblas found: NO (tried pkgconfig)\n",
      "  \u001b[31m   \u001b[0m Run-time dependency openblas found: NO (tried pkgconfig, framework and cmake)\n",
      "  \u001b[31m   \u001b[0m Run-time dependency openblas found: NO (tried pkgconfig, framework and cmake)\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m ../scipy/meson.build:274:9: ERROR: Dependency \"OpenBLAS\" not found, tried pkgconfig, framework and cmake\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m A full log can be found at /private/var/folders/1k/7lydcyq13sl0zlx371zkb4xc0000gn/T/pip-install-ec85wvhl/scipy_299d2e63bbb648998f8b33e0b3749b27/.mesonpy-who4r3qd/meson-logs/meson-log.txt\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[?25h\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for details.\n"
     ]
    }
   ],
   "source": [
    "pip install --no-cache-dir --no-binary :all: --force-reinstall lightgbm --config-setting=cmake.define.USE_GPU=ON\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8eafbf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully.\n",
      "Performing feature engineering...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use mps:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded categories from cache.\n",
      "All features created.\n",
      "\n",
      "Training V11 model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Fatal] GPU Tree Learner was not enabled in this build.\n",
      "Please recompile with CMake option -DUSE_GPU=1\n"
     ]
    },
    {
     "ename": "LightGBMError",
     "evalue": "GPU Tree Learner was not enabled in this build.\nPlease recompile with CMake option -DUSE_GPU=1",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mLightGBMError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 73\u001b[39m\n\u001b[32m     71\u001b[39m \u001b[38;5;66;03m# --- 5. Train and Evaluate ---\u001b[39;00m\n\u001b[32m     72\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mTraining V11 model...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m \u001b[43mpipeline_v11\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train_log\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mEvaluating V11 model...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     75\u001b[39m val_preds_log = pipeline_v11.predict(X_val)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.0/lib/python3.11/site-packages/sklearn/base.py:1363\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1356\u001b[39m     estimator._validate_params()\n\u001b[32m   1358\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1359\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1360\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1361\u001b[39m     )\n\u001b[32m   1362\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1363\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.0/lib/python3.11/site-packages/sklearn/pipeline.py:661\u001b[39m, in \u001b[36mPipeline.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m    655\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._final_estimator != \u001b[33m\"\u001b[39m\u001b[33mpassthrough\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    656\u001b[39m         last_step_params = \u001b[38;5;28mself\u001b[39m._get_metadata_for_step(\n\u001b[32m    657\u001b[39m             step_idx=\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m) - \u001b[32m1\u001b[39m,\n\u001b[32m    658\u001b[39m             step_params=routed_params[\u001b[38;5;28mself\u001b[39m.steps[-\u001b[32m1\u001b[39m][\u001b[32m0\u001b[39m]],\n\u001b[32m    659\u001b[39m             all_params=params,\n\u001b[32m    660\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m661\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_final_estimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mlast_step_params\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfit\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    663\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.0/lib/python3.11/site-packages/lightgbm/sklearn.py:1398\u001b[39m, in \u001b[36mLGBMRegressor.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_init_score, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[39m\n\u001b[32m   1381\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfit\u001b[39m(  \u001b[38;5;66;03m# type: ignore[override]\u001b[39;00m\n\u001b[32m   1382\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1383\u001b[39m     X: _LGBM_ScikitMatrixLike,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1395\u001b[39m     init_model: Optional[Union[\u001b[38;5;28mstr\u001b[39m, Path, Booster, LGBMModel]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   1396\u001b[39m ) -> \u001b[33m\"\u001b[39m\u001b[33mLGBMRegressor\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1397\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Docstring is inherited from the LGBMModel.\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1398\u001b[39m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1399\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1400\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1401\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1402\u001b[39m \u001b[43m        \u001b[49m\u001b[43minit_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43minit_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1403\u001b[39m \u001b[43m        \u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1404\u001b[39m \u001b[43m        \u001b[49m\u001b[43meval_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1405\u001b[39m \u001b[43m        \u001b[49m\u001b[43meval_sample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1406\u001b[39m \u001b[43m        \u001b[49m\u001b[43meval_init_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_init_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1407\u001b[39m \u001b[43m        \u001b[49m\u001b[43meval_metric\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_metric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1408\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfeature_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1409\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcategorical_feature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1410\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1411\u001b[39m \u001b[43m        \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1412\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1413\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.0/lib/python3.11/site-packages/lightgbm/sklearn.py:1049\u001b[39m, in \u001b[36mLGBMModel.fit\u001b[39m\u001b[34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, feature_name, categorical_feature, callbacks, init_model)\u001b[39m\n\u001b[32m   1046\u001b[39m evals_result: _EvalResultDict = {}\n\u001b[32m   1047\u001b[39m callbacks.append(record_evaluation(evals_result))\n\u001b[32m-> \u001b[39m\u001b[32m1049\u001b[39m \u001b[38;5;28mself\u001b[39m._Booster = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1050\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1051\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1052\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mn_estimators\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1053\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalid_sets\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1054\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalid_names\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1055\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfeval\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_metrics_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[32m   1056\u001b[39m \u001b[43m    \u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m=\u001b[49m\u001b[43minit_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1057\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1058\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1060\u001b[39m \u001b[38;5;66;03m# This populates the property self.n_features_, the number of features in the fitted model,\u001b[39;00m\n\u001b[32m   1061\u001b[39m \u001b[38;5;66;03m# and so should only be set after fitting.\u001b[39;00m\n\u001b[32m   1062\u001b[39m \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m   1063\u001b[39m \u001b[38;5;66;03m# The related property self._n_features_in, which populates self.n_features_in_,\u001b[39;00m\n\u001b[32m   1064\u001b[39m \u001b[38;5;66;03m# is set BEFORE fitting.\u001b[39;00m\n\u001b[32m   1065\u001b[39m \u001b[38;5;28mself\u001b[39m._n_features = \u001b[38;5;28mself\u001b[39m._Booster.num_feature()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.0/lib/python3.11/site-packages/lightgbm/engine.py:297\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(params, train_set, num_boost_round, valid_sets, valid_names, feval, init_model, keep_training_booster, callbacks)\u001b[39m\n\u001b[32m    295\u001b[39m \u001b[38;5;66;03m# construct booster\u001b[39;00m\n\u001b[32m    296\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m297\u001b[39m     booster = \u001b[43mBooster\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    298\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_valid_contain_train:\n\u001b[32m    299\u001b[39m         booster.set_train_data_name(train_data_name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.0/lib/python3.11/site-packages/lightgbm/basic.py:3660\u001b[39m, in \u001b[36mBooster.__init__\u001b[39m\u001b[34m(self, params, train_set, model_file, model_str)\u001b[39m\n\u001b[32m   3658\u001b[39m params.update(train_set.get_params())\n\u001b[32m   3659\u001b[39m params_str = _param_dict_to_str(params)\n\u001b[32m-> \u001b[39m\u001b[32m3660\u001b[39m \u001b[43m_safe_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3661\u001b[39m \u001b[43m    \u001b[49m\u001b[43m_LIB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mLGBM_BoosterCreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3662\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain_set\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3663\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_c_str\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams_str\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3664\u001b[39m \u001b[43m        \u001b[49m\u001b[43mctypes\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbyref\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_handle\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3665\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3666\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3667\u001b[39m \u001b[38;5;66;03m# save reference to data\u001b[39;00m\n\u001b[32m   3668\u001b[39m \u001b[38;5;28mself\u001b[39m.train_set = train_set\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.0/lib/python3.11/site-packages/lightgbm/basic.py:313\u001b[39m, in \u001b[36m_safe_call\u001b[39m\u001b[34m(ret)\u001b[39m\n\u001b[32m    305\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Check the return value from C API call.\u001b[39;00m\n\u001b[32m    306\u001b[39m \n\u001b[32m    307\u001b[39m \u001b[33;03mParameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    310\u001b[39m \u001b[33;03m    The return value from C API calls.\u001b[39;00m\n\u001b[32m    311\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    312\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ret != \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m313\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m LightGBMError(_LIB.LGBM_GetLastError().decode(\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "\u001b[31mLightGBMError\u001b[39m: GPU Tree Learner was not enabled in this build.\nPlease recompile with CMake option -DUSE_GPU=1"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import pipeline as hf_pipeline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# --- 1. Load Data ---\n",
    "train_df = pd.read_csv('/Users/adityasharma/Github Projects/Amazon/input/train.csv')\n",
    "train_df = train_df.dropna(subset=['price'])\n",
    "train_df['catalog_content'] = train_df['catalog_content'].astype(str).fillna('')\n",
    "train_df['title'] = train_df['catalog_content'].apply(lambda t: (m.group(1).strip() if (m := re.search(r'^item name:\\s*(.*)', t, re.I | re.M)) else t))\n",
    "print(\"Data loaded successfully.\")\n",
    "\n",
    "# --- 2. Feature Engineering ---\n",
    "print(\"Performing feature engineering...\")\n",
    "# Advanced Categorization\n",
    "classifier = hf_pipeline(\"zero-shot-classification\", model=\"valhalla/distilbart-mnli-12-3\")\n",
    "candidate_labels = ['electronics', 'grocery', 'home goods', 'health & beauty', 'apparel', 'books', 'automotive', 'sports']\n",
    "try:\n",
    "    cached_categories = pd.read_csv('cached_categories_distilbart.csv')\n",
    "    train_df['category'] = cached_categories['category']\n",
    "    print(\"Loaded categories from cache.\")\n",
    "except FileNotFoundError:\n",
    "    titles_to_classify = train_df['title'].tolist()\n",
    "    results = classifier(titles_to_classify, candidate_labels, batch_size=64, multi_label=False)\n",
    "    train_df['category'] = [result['labels'][0] for result in results]\n",
    "    train_df[['category']].to_csv('cached_categories_distilbart.csv', index=False)\n",
    "    print(\"Categorization complete and saved to cache.\")\n",
    "\n",
    "# Brand-Tier Feature\n",
    "train_df['brand'] = train_df['catalog_content'].apply(lambda t: (m.group(1).strip().lower() if (m := re.search(r'^(?:brand|manufacturer):\\s*(.*)', t, re.I | re.M)) and m.group(1) else 'unknown'))\n",
    "avg_price_by_brand = train_df.groupby('brand')['price'].mean().to_dict()\n",
    "train_df['brand_avg_price'] = train_df['brand'].map(avg_price_by_brand).fillna(train_df['price'].median())\n",
    "\n",
    "# --- CORRECTED: Re-integrate the Quantity Feature ---\n",
    "def extract_quantity(text):\n",
    "    text = text.lower()\n",
    "    patterns = [r'pack of (\\d+)', r'(\\d+)\\s*[-]?pack', r'(\\d+)\\s*pk', r'(\\d+)\\s*per case', r'case of (\\d+)', r'(\\d+)\\s*count']\n",
    "    for pattern in patterns:\n",
    "        match = re.search(pattern, text)\n",
    "        if match: return int(match.group(1))\n",
    "    return 1\n",
    "train_df['quantity'] = train_df['catalog_content'].apply(extract_quantity)\n",
    "print(\"All features created.\")\n",
    "\n",
    "# --- 3. Create Hold-Out Set ---\n",
    "feature_cols = ['catalog_content', 'category', 'brand_avg_price', 'quantity']\n",
    "X = train_df[feature_cols]\n",
    "y = train_df['price']\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "y_train_log = np.log1p(y_train)\n",
    "\n",
    "# --- 4. Build the V11 Pipeline ---\n",
    "best_params = { 'objective': 'regression_l1', 'metric': 'mae', 'n_estimators': 761, 'learning_rate': 0.188, 'num_leaves': 41, 'max_depth': 17, 'lambda_l1': 0.04, 'lambda_l2': 2.53e-06, 'feature_fraction': 0.73, 'bagging_fraction': 0.81, 'bagging_freq': 5, 'min_child_samples': 9, 'random_state': 42, 'verbose': -1, 'device': 'gpu', 'n_jobs': -1 }\n",
    "numeric_pipeline = Pipeline(steps=[('imputer', SimpleImputer(strategy='median')), ('scaler', StandardScaler())])\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('text', TfidfVectorizer(stop_words='english', max_features=30000, ngram_range=(1, 2)), 'catalog_content'),\n",
    "    ('category', OneHotEncoder(handle_unknown='ignore'), ['category']),\n",
    "    ('numeric', numeric_pipeline, ['brand_avg_price', 'quantity'])\n",
    "])\n",
    "pipeline_v11 = Pipeline(steps=[('preprocessor', preprocessor), ('regressor', lgb.LGBMRegressor(**best_params))])\n",
    "\n",
    "# --- 5. Train and Evaluate ---\n",
    "print(\"\\nTraining V11 model...\")\n",
    "pipeline_v11.fit(X_train, y_train_log)\n",
    "print(\"\\nEvaluating V11 model...\")\n",
    "val_preds_log = pipeline_v11.predict(X_val)\n",
    "val_preds = np.expm1(val_preds_log)\n",
    "val_preds[val_preds < 0] = 0\n",
    "\n",
    "def smape(y_true, y_pred):\n",
    "    numerator = np.abs(y_pred - y_true)\n",
    "    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2\n",
    "    return np.mean(np.divide(numerator, denominator, out=np.zeros_like(numerator, dtype=float), where=denominator!=0)) * 100\n",
    "\n",
    "v11_smape = smape(y_val, val_preds)\n",
    "\n",
    "print(\"\\n--- Model Performance Comparison ---\")\n",
    "print(f\"V8 Model SMAPE (previous best): 50.9553\") # Using V8 as it was our best so far with numericals\n",
    "print(f\"V11 Model SMAPE (all features): {v11_smape:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4a5a8d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "price_predictor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
