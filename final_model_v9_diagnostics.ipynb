{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e940c272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully.\n",
      "\n",
      "--- Engineering Features ---\n",
      "\n",
      "--- Feature Diagnostics ---\n",
      "Distribution of 'quantity' feature (top 5):\n",
      "quantity\n",
      "1     43663\n",
      "6      5957\n",
      "12     5628\n",
      "2      4636\n",
      "3      3968\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Distribution of 'category' feature (%):\n",
      "category\n",
      "grocery          66.97%\n",
      "unknown          27.08%\n",
      "health_beauty     3.16%\n",
      "home_goods        2.22%\n",
      "electronics       0.57%\n",
      "Name: proportion, dtype: object\n",
      "\n",
      "--- Training Model ---\n",
      "\n",
      "Overall SMAPE on validation set: 51.4851\n",
      "\n",
      "--- Advanced Evaluation Diagnostics ---\n",
      "\n",
      "SMAPE Performance by Category:\n",
      "category\n",
      "unknown          60.713490\n",
      "health_beauty    51.972460\n",
      "home_goods       49.033802\n",
      "grocery          47.832410\n",
      "electronics      38.941247\n",
      "dtype: float64\n",
      "\n",
      "SMAPE Performance by Price Tier:\n",
      "price_tier\n",
      "(0.0, 25.0]        47.709557\n",
      "(25.0, 100.0]      57.725240\n",
      "(100.0, 500.0]     90.726003\n",
      "(500.0, inf]      180.521334\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1k/7lydcyq13sl0zlx371zkb4xc0000gn/T/ipykernel_22977/974476302.py:102: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  category_performance = eval_df.groupby('category').apply(smape_group).sort_values(ascending=False)\n",
      "/var/folders/1k/7lydcyq13sl0zlx371zkb4xc0000gn/T/ipykernel_22977/974476302.py:109: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  tier_performance = eval_df.groupby('price_tier').apply(smape_group)\n",
      "/var/folders/1k/7lydcyq13sl0zlx371zkb4xc0000gn/T/ipykernel_22977/974476302.py:109: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  tier_performance = eval_df.groupby('price_tier').apply(smape_group)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import lightgbm as lgb\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# ==============================================================================\n",
    "# ## 1. Setup and Data Loading\n",
    "# ==============================================================================\n",
    "train_df = pd.read_csv('/Users/adityasharma/Github Projects/Amazon/input/train.csv')\n",
    "train_df = train_df.dropna(subset=['price'])\n",
    "train_df['catalog_content'] = train_df['catalog_content'].astype(str).fillna('')\n",
    "print(\"Data loaded successfully.\")\n",
    "\n",
    "# ==============================================================================\n",
    "# ## 2. Feature Engineering\n",
    "# ==============================================================================\n",
    "print(\"\\n--- Engineering Features ---\")\n",
    "# --- Feature Functions ---\n",
    "def extract_quantity(text):\n",
    "    text = text.lower(); patterns = [r'pack of (\\d+)', r'(\\d+)\\s*[-]?pack', r'(\\d+)\\s*pk', r'(\\d+)\\s*per case', r'case of (\\d+)', r'(\\d+)\\s*count'];\n",
    "    for p in patterns:\n",
    "        m=re.search(p,text)\n",
    "        if m: return int(m.group(1))\n",
    "    return 1\n",
    "\n",
    "def categorize_product(text):\n",
    "    text = text.lower()\n",
    "    category_map = {\n",
    "        'electronics': ['phone', 'camera', 'tv', 'laptop', 'headphone', 'cable', 'charger'],\n",
    "        'grocery': ['coffee', 'tea', 'snack', 'chocolate', 'organic', 'sugar', 'gluten free', 'sauce', 'candy'],\n",
    "        'home_goods': ['shed', 'furniture', 'kitchen', 'decor', 'towel', 'blanket', 'pillow'],\n",
    "        'health_beauty': ['cream', 'shampoo', 'lotion', 'vitamin', 'supplement']\n",
    "    }\n",
    "    for cat, keys in category_map.items():\n",
    "        if any(key in text for key in keys): return cat\n",
    "    return 'unknown'\n",
    "\n",
    "# --- Apply Feature Functions ---\n",
    "numerical_features_df = pd.json_normalize(train_df['catalog_content'].apply(lambda t: {f'feat_{u}': float(m.group(1)) for u, m in {'gb': re.search(r'(\\d+\\.?\\d*)\\s*gb', t.lower()), 'oz': re.search(r'(\\d+\\.?\\d*)\\s*(?:oz|ounce)', t.lower()), 'inch': re.search(r'(\\d+\\.?\\d*)\\s*(?:inch|\")', t.lower())}.items() if m}))\n",
    "train_df = pd.concat([train_df.reset_index(drop=True), numerical_features_df], axis=1)\n",
    "train_df['quantity'] = train_df['catalog_content'].apply(extract_quantity)\n",
    "train_df['category'] = train_df['catalog_content'].apply(categorize_product)\n",
    "\n",
    "# ==============================================================================\n",
    "# ## 2.1 NEW: Feature Creation Diagnostics\n",
    "# ==============================================================================\n",
    "print(\"\\n--- Feature Diagnostics ---\")\n",
    "print(\"Distribution of 'quantity' feature (top 5):\")\n",
    "print(train_df['quantity'].value_counts().head())\n",
    "print(\"\\nDistribution of 'category' feature (%):\")\n",
    "print(train_df['category'].value_counts(normalize=True).apply(lambda x: f\"{x:.2%}\"))\n",
    "\n",
    "# ==============================================================================\n",
    "# ## 3. Model Training and Evaluation\n",
    "# ==============================================================================\n",
    "numerical_cols = [col for col in train_df.columns if col.startswith('feat_')]\n",
    "X = train_df[['catalog_content', 'quantity', 'category'] + numerical_cols]\n",
    "y = train_df['price']\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "y_train_log = np.log1p(y_train)\n",
    "\n",
    "best_params = { 'objective': 'regression_l1', 'metric': 'mae', 'n_estimators': 761, 'learning_rate': 0.188, 'num_leaves': 41, 'max_depth': 17, 'lambda_l1': 0.04, 'lambda_l2': 2.53e-06, 'feature_fraction': 0.73, 'bagging_fraction': 0.81, 'bagging_freq': 5, 'min_child_samples': 9, 'random_state': 42, 'n_jobs': -1, 'verbose': -1 }\n",
    "numeric_pipeline = Pipeline(steps=[('imputer', SimpleImputer(strategy='constant', fill_value=0)), ('scaler', StandardScaler())])\n",
    "preprocessor = ColumnTransformer(transformers=[('text', TfidfVectorizer(stop_words='english', max_features=30000, ngram_range=(1, 2)), 'catalog_content'), ('category', OneHotEncoder(handle_unknown='ignore'), ['category']), ('numeric', numeric_pipeline, ['quantity'] + numerical_cols)])\n",
    "pipeline = Pipeline(steps=[('preprocessor', preprocessor), ('regressor', lgb.LGBMRegressor(**best_params))])\n",
    "\n",
    "print(\"\\n--- Training Model ---\")\n",
    "pipeline.fit(X_train, y_train_log)\n",
    "val_preds_log = pipeline.predict(X_val)\n",
    "val_preds = np.expm1(val_preds_log)\n",
    "val_preds[val_preds < 0] = 0\n",
    "\n",
    "def smape(y_true, y_pred):\n",
    "    numerator = np.abs(y_pred - y_true)\n",
    "    denominator = (np.abs(y_true) + np.abs(y_pred)) / 2\n",
    "    return np.mean(np.divide(numerator, denominator, out=np.zeros_like(numerator, dtype=float), where=denominator!=0)) * 100\n",
    "\n",
    "overall_smape = smape(y_val, val_preds)\n",
    "print(f\"\\nOverall SMAPE on validation set: {overall_smape:.4f}\")\n",
    "\n",
    "# ==============================================================================\n",
    "# ## 4. NEW: Advanced Evaluation Diagnostics\n",
    "# ==============================================================================\n",
    "print(\"\\n--- Advanced Evaluation Diagnostics ---\")\n",
    "# Create a DataFrame for analysis\n",
    "eval_df = X_val.copy()\n",
    "eval_df['price'] = y_val\n",
    "eval_df['predicted_price'] = val_preds\n",
    "\n",
    "# --- Per-Category SMAPE ---\n",
    "def smape_group(group):\n",
    "    return smape(group['price'], group['predicted_price'])\n",
    "\n",
    "category_performance = eval_df.groupby('category').apply(smape_group).sort_values(ascending=False)\n",
    "print(\"\\nSMAPE Performance by Category:\")\n",
    "print(category_performance)\n",
    "\n",
    "# --- Price Tier SMAPE ---\n",
    "price_bins = [0, 25, 100, 500, np.inf]\n",
    "eval_df['price_tier'] = pd.cut(eval_df['price'], bins=price_bins)\n",
    "tier_performance = eval_df.groupby('price_tier').apply(smape_group)\n",
    "print(\"\\nSMAPE Performance by Price Tier:\")\n",
    "print(tier_performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7fb84e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (housing-price-prediction)",
   "language": "python",
   "name": "housing-price-prediction"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
